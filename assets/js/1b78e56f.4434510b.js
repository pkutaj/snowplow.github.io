"use strict";(self.webpackChunkdocsite_poc_github_io=self.webpackChunkdocsite_poc_github_io||[]).push([[37096],{3905:(e,r,t)=>{t.d(r,{Zo:()=>c,kt:()=>d});var n=t(67294);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function a(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?a(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,n,o=function(e,r){if(null==e)return{};var t,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=n.createContext({}),p=function(e){var r=n.useContext(l),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},c=function(e){var r=p(e.components);return n.createElement(l.Provider,{value:r},e.children)},u={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},m=n.forwardRef((function(e,r){var t=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=p(t),d=o,v=m["".concat(l,".").concat(d)]||m[d]||u[d]||a;return t?n.createElement(v,i(i({ref:r},c),{},{components:t})):n.createElement(v,i({ref:r},c))}));function d(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=m;var s={};for(var l in r)hasOwnProperty.call(r,l)&&(s[l]=r[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var p=2;p<a;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}m.displayName="MDXCreateElement"},16400:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var n=t(87462),o=(t(67294),t(3905));const a={title:"Monitoring",date:"2020-08-26",sidebar_position:40},i=void 0,s={unversionedId:"managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/index",id:"managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/index",title:"Monitoring",description:"When running a recovery job in your production pipeline, you'll likely find it useful to keep an eye on it's progress.",source:"@site/docs/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/index.md",sourceDirName:"managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring",slug:"/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/",permalink:"/docs/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/",draft:!1,editUrl:"https://github.com/snowplow/snowplow.github.io/tree/main/docs/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/monitoring/index.md",tags:[],version:"current",lastUpdatedAt:1661352356,formattedLastUpdatedAt:"Aug 24, 2022",sidebarPosition:40,frontMatter:{title:"Monitoring",date:"2020-08-26",sidebar_position:40},sidebar:"tutorialSidebar",previous:{title:"Spark",permalink:"/docs/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/running/spark/"},next:{title:"Troubleshooting",permalink:"/docs/managing-data-quality/event-recovery-for-bdp-users/manual-event-recovery-for-snowplow-bdp/troubleshooting/"}},l={},p=[{value:"Amazon EMR",id:"amazon-emr",level:3},{value:"Google Dataflow",id:"google-dataflow",level:3}],c={toc:p};function u(e){let{components:r,...t}=e;return(0,o.kt)("wrapper",(0,n.Z)({},c,t,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"When running a recovery job in your production pipeline, you'll likely find it useful to keep an eye on it's progress."),(0,o.kt)("p",null,"In order to verify the process is running properly there are several locations in your\xa0",(0,o.kt)("strong",{parentName:"p"},"infrastructure"),"\xa0that can be monitored, depending on your runtime environment. These are: datasinks (for recovery job processed output):\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"failedOutput"),"\xa0(S3/GCS bucket),\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"unrecoverableOutput"),"\xa0(S3/GCS bucket),\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"output"),"\xa0(Kinesis/PubSub streams) and job runners (tracking job status and processing in real-time)."),(0,o.kt)("p",null,"Beyond monitoring infrastructure, each job exposes \u201cbusiness\u201d processing metrics that summarise failed, unrecoverable and recovered bad rows that have been processed."),(0,o.kt)("h3",{id:"amazon-emr"},"Amazon EMR"),(0,o.kt)("p",null,"On EMR recovery job exposes run summary using a\xa0",(0,o.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/monitoring.html"},"built-in reporting library delivering")," count summaries for:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"event-recovery.driver.summary.Recovered")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"event-recovery.driver.summary.Failed")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"event-recovery.driver.summary.Unrecoverable"))),(0,o.kt)("p",null,"The metrics can be accessed trough variety of ways (sinks) and can be configured upon cluster creation parameters."),(0,o.kt)("p",null,"To enable desired sink set EMR\u2019s\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"spark-metrics"),"\xa0classification parameters following ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/apache/spark/blob/master/conf/metrics.properties.template"},"possible values")," using EMR\u2019s classifiers."),(0,o.kt)("p",null,"To expose metrics over http accessible at\xa0",(0,o.kt)("inlineCode",{parentName:"p"},"http://${SPARK_HOST}:4040/metrics/json"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'  {\n    "classification": "spark-metrics",\n    "properties": {\n        "spark.metrics.namespace": "event-revovery",\n        "*.sink.servlet.class": "org.apache.spark.metrics.sink.MetricsServlet",\n        "*.sink.servlet.period": "1",\n        "*.sink.servlet.unit": "seconds",\n        "*.sink.servlet.path": "/metrics/json",\n        "master.sink.servlet.path": "/metrics/master/json",\n        "applications.sink.servlet.path": "metrics/applications/json",\n        "*.source.metrics.class": "org.apache.spark.metrics.source.Metrics"\n\n    }\n')),(0,o.kt)("p",null,"To push metrics to output logs to console appender:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'  {\n    "classification": "spark-metrics",\n    "properties": {\n        "spark.metrics.namespace": "$name",\n        "*.sink.console.class": "org.apache.spark.metrics.sink.ConsoleSink",\n        "*.source.metrics.class": "org.apache.spark.metrics.source.Metrics"\n\n    }\n')),(0,o.kt)("p",null,"For more sinks see\xa0",(0,o.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/monitoring.html"},"Spark documentation on monitoring"),"."),(0,o.kt)("h3",{id:"google-dataflow"},"Google Dataflow"),(0,o.kt)("p",null,"On Google Dataflow recovery job exposes realtime run metrics using a dataflow\u2019s native functions. The metrics are:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"recovered")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"failed")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"unrecoverable"))),(0,o.kt)("p",null,"The metrics can be accessed through the web UI directly in Dataflow."))}u.isMDXComponent=!0}}]);